#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Functions for transforming data.


It considers the following tensor format:

    (N, C, D, H, W)

where N is the number in the bach, C is the channel (physical
quantity), D is the time frame (time dimension), H and W are
the 2D solution grid indexes.


All manipulations consider a 2D field, modifications are
necessary to account for a 3D field. Some functions are inspired
on the torchvision source code:

https://github.com/pytorch/vision/blob/master/torchvision/transforms/

"""


# native modules
##none##

# third-party modules
import torch

# local modules
##none##


def mean(tensor):
    """ Calculate mean of arrays defined by the last
    2 dimensions of tensor.
    """
    return tensor.view(
        tensor.shape[:-2].numel(), -1
                      ).mean(-1,dtype=tensor.dtype
                            ).view(tensor.shape[:-2])



def std(tensor):
    """ Calculate standard deviation of arrays defined by the last
    2 dimensions of tensor.
    """
    return tensor.view(
        tensor.shape[:-2].numel(), -1
                      ).std(-1,
                           ).view(tensor.shape[:-2])



def std_first_frame(tensor):
    """ Calculate std of the first frame (third dimension).

    ----------    
    ARGUMENTS

        tensor: tensor image of size (N, C, D, ... , H, W).

    ----------                 
    RETURNS

        tensor: tensor image of the std of the first frame in
                the format (N, C, 1, ..., 1, 1)

    """
    
    # calculate the std of the first frame (dimension 2), all channels
    std_frame = std(tensor[:,:,0].clone())
    
    # adds the frame dimension back and 2 dimensions at the end to allow 
    # broadcasting
    return std_frame.unsqueeze(2)[(...,) + (None,)*2]



def mean_first_frame(tensor):
    """ Calculate mean of the first frame (third dimension).

    ----------    
    ARGUMENTS

        tensor: tensor image of size (N, C, D, ... , H, W).

    ----------                 
    RETURNS

        tensor: tensor image of the std of the first frame in
                the format (N, C, 1, ..., 1, 1)

    """
    
    # calculate the std of the first frame (dimension 1), all channels
    mean_frame = mean(tensor[:,:,0].clone())
    
    # adds the frame dimension back and 2 dimensions at the end to allow 
    # broadcasting
    return mean_frame.unsqueeze(2)[(...,) + (None,)*2]



def multiply_frame_(tensor, frame, factors):
    """ Multiple every frame (third dimension) by individual values 
    considering a channel (second dimension) independent factor.
    
    In-place operation (mutates input tensor!).
    
    ----------    
    ARGUMENTS
    
        tensor: tensor image of size (N, C, D, ..., H, W) to be modified.
        frame: tensor with the multiplying scalars for every frame
               (third dimension), all other dimensions (except the
               2D array) must be the same. The format generated by
               mean_first_frame or std_first_frame.
        factors: tensor with the value for scaling the multiplication
                 for each channel (must have as much values as channels -
                 second dimension). Ex: if [3, 1, 2], the first
                 channel is multiplied by 3*frame[:,:,0], the second by 
                 1*frame[:,:,1] and the third by 2*frame[:,:,2].
    
    ----------                 
    RETURNS

        tensor: tensor image of multiplied tensor.
    
    """
    
    frame = frame.clone()
    for index, factor in enumerate(factors):
        frame[:,index] = frame[:,index]*factor
        
    return tensor.mul_(frame)



def divide_frame_(tensor, frame, factors):
    """ Divide every frame (third dimension) by individual values 
    considering a channel (second dimension) independent factor.
    
    In-place operation (mutates input tensor!).
    
    ----------
    ARGUMENTS
    
        tensor: tensor image of size (N, C, D, ..., H, W) to be modified.
        frame: tensor with the dividing scalars for every frame
               (third dimension), all other dimensions (except the
               2D array) must be the same. The format generated by
               mean_first_frame or std_first_frame.
        factors: tensor with the value for scaling the multiplication
                 for each channel (must have as much values as channels -
                 second dimension). Ex: if [3, 1, 2], the first
                 channel is divided by 3*frame[:,0], the second by 
                 1*frame[:,1] and the third by 2*frame[:,2].
    
    ----------         
    RETURNS

        tensor: tensor image of multiplied tensor.
    
    """
    
    frame = frame.clone()
    for index, factor in enumerate(factors):
        frame[:,index] = frame[:,index]*factor
        
    return tensor.div_(frame)



def add_frame_(tensor, frame, factors):
    """ Add to every frame (third dimension) individual values 
    considering a channel (second dimension) independent factor.
    
    In-place operation (mutates input tensor!).
    
    ----------    
    ARGUMENTS
    
        tensor: tensor image of size (N, C, D, ..., H, W) to be modified.
        frame: tensor with the dividing scalars for every frame
               (third dimension), all other dimensions (except the
               2D array) must be the same. The format generated by
               mean_first_frame or std_first_frame.
        factors: tensor with the value for scaling the addition
                 for each channel (must have as much values as channels -
                 second dimension). Ex: if [3, 1, 2], the first
                 channel is added with 3*frame[:,0], the second by 
                 1*frame[:,1] and the third by 2*frame[:,2].
    
    ----------                 
    RETURNS

        tensor: tensor image of multiplied tensor.
    
    """
    
    frame = frame.clone()
    for index, factor in enumerate(factors):
        frame[:,index] = frame[:,index]*factor
        
    return tensor.add_(frame)



def offset_(tensor, scalars):       
    """ Apply an offset for the each channel in the tensor. 

    In-place operation (modifies input tensor!). Channel must be
    the second dimension!

    ----------
    ARGUMENTS

        tensor: tensor image of size (N, C, ..., H, W) to be
                modified.
        scalars: tensor with the scalar to add in each channel

    ----------
    RETURNS

        tensor: tensor image with offset.

    """

    # tensor corresponding to single channel scalar
    base_transform_shape = list(tensor.shape[:-2])
    # single dimension for channel
    base_transform_shape[1] = 1
    
    base_offset = torch.ones(base_transform_shape,
                             dtype=tensor.dtype,
                             device=tensor.device).unsqueeze(-1)
    
    # start the tensor that will de added to the input tensor
    offsets = base_offset*scalars[0]
    for scalar in scalars[1:]:
        offsets = torch.cat((offsets, base_offset*scalar),
                              dim=1)
    
    return tensor.view(*tensor.shape[:-2], -1
               ).add_(offsets).view(tensor.shape)



def multiply_(tensor, scalars):       
    """ Apply a multiplication for the each channel in the tensor. 

    In-place operation (modifies input tensor!). Channel must be
    the second dimension!

    ----------
    ARGUMENTS

        tensor: tensor image of size (N, C, ..., H, W) to be
                modified.
        scalars: tensor with the scalar to multiply in each channel

    ----------
    RETURNS

        tensor: tensor image with offset.

    """

    # tensor corresponding to single channel scalar
    base_transform_shape = list(tensor.shape[:-2])
    # single dimension for channel
    base_transform_shape[1] = 1
    
    # tensor corresponding to single channel scalar
    base_offset = torch.ones(base_transform_shape,
                             dtype=tensor.dtype,
                             device=tensor.device).unsqueeze(-1)

    # start the tensor that will de added to the input tensor
    offsets = base_offset*scalars[0]

    for scalar in scalars[1:]:
        offsets = torch.cat((offsets, base_offset*scalar),
                             dim=1)
        
    return tensor.view(*tensor.shape[:-2], -1
               ).mul_(offsets).view(tensor.shape)



"""
Data augmentation functions and classes
"""
class RandomFlip():
    """ In-place flips of the last 2 dimensions of a tensor
    
    Options:
    
        0 : no flip
        1 : flip vertical (-y)
        2 : flip horizontal (-x)
        3 : flip horizontal & vertical (-x, -y)
        
    """
    def __init__(self):
        self.flips = [self.no_flip_,
                      self.flip_vertical_,
                      self.flip_horizontal_,
                      self.flip_both_]
    
    def no_flip_(self, data):
        pass
        
    def flip_horizontal_(self, data):
        data.data = torch.flip(data, dims=[-1])
        
    def flip_vertical_(self, data):
        data.data = torch.flip(data, dims=[-2])
        
    def flip_both_(self, data):
        data.data = torch.flip(data, dims=[-2,-1])
        
    def __call__(self, data):
        """ Apply a random flip.
        
        Gets a random integer between 0 and 3 to select the
        flip operation to apply.
        
        ----------
        ARGUMENTS
        
            data: tensor to flip. Operation is performed
                  in-place
        
        """        
        d4dice = torch.randint(high=4,size=(1,))
        self.flips[d4dice](data)
        
        